{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from super_gradients.training import models\n",
    "# from super_gradients.common.object_names import Models\n",
    "# import onnx\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "# # CONFIG\n",
    "# NO_CLASSES=2\n",
    "# batch_size = 1\n",
    "# topk_all = 100\n",
    "# input_shape = (3, 640, 640)\n",
    "# iou_thres=0.45\n",
    "# score_thres=0.25\n",
    "# end2end=True\n",
    "# onnx_path = os.path.join('', \"best_ds.onnx\")\n",
    "\n",
    "# # net = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")\n",
    "# net = models.get(Models.YOLO_NAS_L, num_classes=NO_CLASSES,\n",
    "#                 checkpoint_path='./checkpoints/firesmokes/ckpt_best.pth')\n",
    "\n",
    "# class TRT_NMS(torch.autograd.Function):\n",
    "#     '''TensorRT NMS operation'''\n",
    "#     @staticmethod\n",
    "#     def forward(\n",
    "#         ctx,\n",
    "#         boxes,\n",
    "#         scores,\n",
    "#         background_class=-1,\n",
    "#         box_coding=0,\n",
    "#         iou_threshold=0.45,\n",
    "#         max_output_boxes=100,\n",
    "#         plugin_version=\"1\",\n",
    "#         score_activation=0,\n",
    "#         score_threshold=0.25,\n",
    "#         class_agnostic=1\n",
    "#     ):\n",
    "#         batch_size, num_boxes, num_classes = scores.shape\n",
    "#         num_det = torch.randint(0, max_output_boxes, (batch_size, 1), dtype=torch.int32)\n",
    "#         det_boxes = torch.randn(batch_size, max_output_boxes, 4)\n",
    "#         det_scores = torch.randn(batch_size, max_output_boxes)\n",
    "#         det_classes = torch.randint(0, num_classes, (batch_size, max_output_boxes), dtype=torch.int32)\n",
    "#         return num_det, det_boxes, det_scores, det_classes\n",
    "\n",
    "#     @staticmethod\n",
    "#     def symbolic(g,\n",
    "#                  boxes,\n",
    "#                  scores,\n",
    "#                  background_class=-1,\n",
    "#                  box_coding=0,\n",
    "#                  iou_threshold=0.45,\n",
    "#                  max_output_boxes=100,\n",
    "#                  plugin_version=\"1\",\n",
    "#                  score_activation=0,\n",
    "#                  score_threshold=0.25,\n",
    "#                  class_agnostic=1\n",
    "#                  ):\n",
    "#         out = g.op(\"TRT::EfficientNMS_TRT\",\n",
    "#                    boxes,\n",
    "#                    scores,\n",
    "#                    background_class_i=background_class,\n",
    "#                    box_coding_i=box_coding,\n",
    "#                    iou_threshold_f=iou_threshold,\n",
    "#                    max_output_boxes_i=max_output_boxes,\n",
    "#                    plugin_version_s=plugin_version,\n",
    "#                    class_agnostic_i=class_agnostic,\n",
    "#                    score_activation_i=score_activation,\n",
    "#                    score_threshold_f=score_threshold,\n",
    "#                    outputs=4)\n",
    "#         nums, boxes, scores, classes = out\n",
    "#         return nums, boxes, scores, classes\n",
    "\n",
    "# class ONNX_TRT(nn.Module):\n",
    "#     '''onnx module with TensorRT NMS operation.'''\n",
    "#     def __init__(self, max_obj=100, iou_thres=0.45, score_thres=0.25, max_wh=None ,device=None, n_classes=80):\n",
    "#         super().__init__()\n",
    "#         assert max_wh is None\n",
    "#         self.device = device if device else torch.device('cpu')\n",
    "#         self.background_class = -1,\n",
    "#         self.box_coding = 0,\n",
    "#         self.iou_threshold = iou_thres\n",
    "#         self.max_obj = max_obj\n",
    "#         self.plugin_version = '1'\n",
    "#         self.score_activation = 0\n",
    "#         self.score_threshold = score_thres\n",
    "#         self.n_classes=n_classes\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         boxes, confscores = x\n",
    "#         num_det, det_boxes, det_scores, det_classes = TRT_NMS.apply(boxes, confscores, self.background_class, self.box_coding,\n",
    "#                                                                     self.iou_threshold, self.max_obj,\n",
    "#                                                                     self.plugin_version, self.score_activation,\n",
    "#                                                                     self.score_threshold)\n",
    "#         return num_det, det_boxes, det_scores, det_classes\n",
    "\n",
    "# net.eval()\n",
    "# net.prep_model_for_conversion()\n",
    "\n",
    "# # https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/BenchmarkingYoloNAS.md\n",
    "# if (end2end):\n",
    "#     onnx_path = os.path.splitext(onnx_path)[0] + \"_nms\" + \".onnx\"\n",
    "#     NMS = ONNX_TRT(\n",
    "#         max_obj=topk_all, iou_thres=iou_thres, score_thres=score_thres, max_wh=None ,device=None, n_classes=NO_CLASSES\n",
    "#     )\n",
    "#     NMS.eval()\n",
    "#     onnx_export_kwargs = {\n",
    "#         'input_names' : ['images'],\n",
    "#         'output_names' : [\"num_dets\", \"det_boxes\", \"det_scores\", \"det_classes\"]\n",
    "#     }\n",
    "#     models.convert_to_onnx(model=net, input_shape=input_shape, post_process=NMS, out_path=onnx_path,\n",
    "#                            torch_onnx_export_kwargs=onnx_export_kwargs)\n",
    "# else:\n",
    "#     models.convert_to_onnx(model=net, input_shape=input_shape, out_path=onnx_path)\n",
    "\n",
    "# # set output dimensions\n",
    "# # note: this makes no functional difference, just explicitly labels output dims\n",
    "# # so can be understood better when onnx inspected with netron etc.\n",
    "# shapes = [batch_size, 1,\n",
    "#           batch_size, topk_all, 4,\n",
    "#           batch_size, topk_all,\n",
    "#           batch_size, topk_all]\n",
    "# onnx_model = onnx.load(onnx_path)  # load onnx model\n",
    "# onnx.checker.check_model(onnx_model)  # check onnx model\n",
    "# for i in onnx_model.graph.output:\n",
    "#     for j in i.type.tensor_type.shape.dim:\n",
    "#         j.dim_param = str(shapes.pop(0))\n",
    "# onnx.save(onnx_model, onnx_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
